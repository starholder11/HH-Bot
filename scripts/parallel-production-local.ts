#!/usr/bin/env tsx

import { ParallelIngestionService, ContentItem } from '../lib/parallel-ingestion';
import { LanceDBIngestionService } from '../lib/lancedb-ingestion-backup';
import { listMediaAssets } from '../lib/media-storage';
import fs from 'fs';
import path from 'path';
import matter from 'gray-matter';
import './bootstrap-env';

interface TextContent {
  slug: string;
  title: string;
  description?: string;
  content: string;
  frontmatter: any;
  file_path: string;
}

/**
 * Load text content from local files instead of GitHub
 */
async function loadLocalTextContent(): Promise<TextContent[]> {
  const contents: TextContent[] = [];
  const timelineDir = path.join(process.cwd(), 'content/timeline');

  if (!fs.existsSync(timelineDir)) {
    console.log('üìÅ No local timeline directory found');
    return contents;
  }

  const entries = fs.readdirSync(timelineDir);
  console.log(`üìÅ Found ${entries.length} timeline entries locally`);

  for (const entry of entries) {
    const entryDir = path.join(timelineDir, entry);
    if (!fs.statSync(entryDir).isDirectory()) continue;

    const contentFile = path.join(entryDir, 'content.mdx');
    const yamlFile = path.join(entryDir, 'index.yaml');

    if (fs.existsSync(contentFile)) {
      try {
        const fileContent = fs.readFileSync(contentFile, 'utf-8');
        const { data: frontmatter, content } = matter(fileContent);

        // Try to get title from YAML file
        let title = entry;
        if (fs.existsSync(yamlFile)) {
          const yamlContent = fs.readFileSync(yamlFile, 'utf-8');
          const titleMatch = yamlContent.match(/^title:\s*(.+)$/m);
          if (titleMatch) {
            title = titleMatch[1].trim().replace(/^['"]|['"]$/g, '');
          }
        }

        contents.push({
          slug: entry,
          title,
          description: frontmatter.description,
          content,
          frontmatter,
          file_path: contentFile,
        });
      } catch (error) {
        console.warn(`‚ö†Ô∏è Failed to process ${entry}:`, error);
      }
    }
  }

  console.log(`‚úÖ Loaded ${contents.length} text files locally`);
  return contents;
}

/**
 * Production-compatible parallel ingestion that uses existing /add endpoint
 * with high concurrency for massive speed improvements
 */
class ProductionParallelIngestion extends ParallelIngestionService {

  /**
   * Override to use single /add calls with high concurrency
   * instead of bulk operations
   */
  async bulkInsertToLanceDB(records: any[]): Promise<void> {
    console.log(`üì¶ Parallel inserting ${records.length} records to production LanceDB...`);
    console.log(`üîó Using production URL: ${this.LANCEDB_API_URL}/add`);

    const CONCURRENCY = 25; // High concurrency for /add calls
    const errors: any[] = [];
    let successCount = 0;

    // Process records in highly concurrent batches
    for (let i = 0; i < records.length; i += CONCURRENCY) {
      const batch = records.slice(i, i + CONCURRENCY);
      const batchNum = Math.floor(i / CONCURRENCY) + 1;
      const totalBatches = Math.ceil(records.length / CONCURRENCY);

      console.log(`‚ö° Processing parallel batch ${batchNum}/${totalBatches} (${batch.length} records)...`);

      // Execute all /add calls in parallel
      const results = await Promise.allSettled(
        batch.map(async (record, idx) => {
          try {
            const response = await fetch(`${this.LANCEDB_API_URL}/add`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(record)
            });

            if (!response.ok) {
              const errorText = await response.text();
              throw new Error(`Record ${i + idx} failed: ${response.status} ${errorText}`);
            }

            return { success: true, index: i + idx };
          } catch (error) {
            return { success: false, index: i + idx, error };
          }
        })
      );

      // Process results
      results.forEach((result, idx) => {
        if (result.status === 'fulfilled' && result.value.success) {
          successCount++;
        } else {
          const error = result.status === 'rejected' ? result.reason : result.value.error;
          errors.push({ index: i + idx, error: error.message });
          console.error(`‚ùå Record ${i + idx} failed:`, error.message);
        }
      });

      console.log(`‚úÖ Batch ${batchNum}/${totalBatches} complete: ${successCount}/${i + batch.length} successful`);

      // Small delay to avoid overwhelming the service
      if (i + CONCURRENCY < records.length) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }

    if (errors.length > 0) {
      console.log(`‚ö†Ô∏è  ${errors.length} records failed, ${successCount} succeeded`);
      if (errors.length > records.length * 0.1) { // More than 10% failed
        throw new Error(`Too many failures: ${errors.length}/${records.length} records failed`);
      }
    } else {
      console.log(`üéâ All ${successCount} records inserted successfully!`);
    }
  }
}

async function buildProductionIndex() {
  console.log('üîß Building production search index...');

  const LANCEDB_API_URL = process.env.LANCEDB_API_URL;

  try {
    const response = await fetch(`${LANCEDB_API_URL}/build-index`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({})
    });

    if (!response.ok) {
      throw new Error(`Index build failed: ${response.status}`);
    }

    console.log('‚úÖ Production search index built successfully');
  } catch (error) {
    console.error('‚ùå Index build failed:', error);
    throw error;
  }
}

async function testProductionSearch() {
  console.log('üß™ Testing production search functionality...');

  const LANCEDB_API_URL = process.env.LANCEDB_API_URL;

  const testQueries = [
    'music audio content',
    'video analysis',
    'text content'
  ];

  for (const query of testQueries) {
    try {
      console.log(`üîç Testing query: "${query}"`);

      const response = await fetch(`${LANCEDB_API_URL}/search`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query, limit: 3 })
      });

      if (!response.ok) {
        throw new Error(`Search failed: ${response.status}`);
      }

      const results = await response.json();
      console.log(`‚úÖ Found ${results.length} results for "${query}"`);

    } catch (error) {
      console.error(`‚ùå Search test failed for "${query}":`, error);
    }
  }
}

async function productionParallelIngestion() {
  console.log('üöÄ PRODUCTION PARALLEL INGESTION WITH PERSISTENT STORAGE');
  console.log('üîí Using EFS persistent storage - data will survive restarts!');
  console.log('‚ö° High concurrency with existing /add endpoint');
  console.log('üìÅ Using local content files (no GitHub token required)');
  console.log('=' * 70);

  const overallStartTime = Date.now();

  try {
    // Initialize services
    const parallelService = new ProductionParallelIngestion();

    // Step 1: Check current production state
    console.log('\nüìä Step 1: Checking production state...');

    const LANCEDB_API_URL = process.env.LANCEDB_API_URL;
    const countResponse = await fetch(`${LANCEDB_API_URL}/count`);

    if (countResponse.ok) {
      const { count } = await countResponse.json();
      console.log(`üìä Current production records: ${count}`);
      console.log(`‚úÖ EFS persistent storage is working - data persisted!`);
    }

    // Step 2: Load all content from local files
    console.log('\nüìÅ Step 2: Loading all content from local files...');

    const [mediaAssets, textContents] = await Promise.all([
      listMediaAssets(),
      loadLocalTextContent()
    ]);

    console.log(`‚úÖ Loaded ${mediaAssets.assets.length} media assets`);
    console.log(`‚úÖ Loaded ${textContents.length} text documents`);

    // Log media breakdown
    const mediaByType = mediaAssets.assets.reduce((acc, asset) => {
      acc[asset.media_type] = (acc[asset.media_type] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);

    console.log('üìä Media assets by type:');
    Object.entries(mediaByType).forEach(([type, count]) => {
      console.log(`   - ${type}: ${count}`);
    });

    // Step 3: Convert to unified ContentItem format
    console.log('\nüîÑ Step 3: Converting to unified format...');

    const mediaItems: ContentItem[] = mediaAssets.assets.map(asset =>
      ParallelIngestionService.mediaAssetToContentItem(asset)
    );

    const textItems: ContentItem[] = textContents.map(text => ({
      id: text.slug,
      title: text.title,
      content_type: 'text',
      combinedText: `${text.title}\n${text.description || ''}\n${text.content}`,
      metadata: {
        file_path: text.file_path,
        frontmatter: text.frontmatter
      }
    }));

    const allItems = [...textItems, ...mediaItems];
    console.log(`üì¶ Total items to process: ${allItems.length}`);

    // Step 4: PRODUCTION PARALLEL INGESTION WITH PERSISTENT STORAGE
    console.log('\nüöÄ Step 4: PRODUCTION PARALLEL INGESTION');
    console.log('üîí Data will be permanently stored in EFS');
    console.log('‚ö° Using high-concurrency /add calls for maximum speed');

    await parallelService.ingestWithOptimizations(allItems);

    // Step 5: Build search index
    console.log('\nüîß Step 5: Building production search index...');
    await buildProductionIndex();

    // Step 6: Test search functionality
    console.log('\nüß™ Step 6: Testing production search functionality...');
    await testProductionSearch();

    // Step 7: Final verification
    console.log('\nüìä Step 7: Final verification...');

    const finalCountResponse = await fetch(`${LANCEDB_API_URL}/count`);

    if (finalCountResponse.ok) {
      const { count } = await finalCountResponse.json();
      console.log(`‚úÖ Final production record count: ${count}`);

      if (count >= allItems.length + 5) { // +5 for existing test records
        console.log('üéâ All items successfully ingested to production!');
        console.log('üîí Data is permanently stored in EFS persistent storage');
      } else {
        console.log(`‚ö†Ô∏è  Record count: ${count} (expected ~${allItems.length + 5})`);
      }
    }

    const totalTime = Date.now() - overallStartTime;
    const originalTime = 90 * 60 * 1000; // 90 minutes in ms
    const speedup = originalTime / totalTime;

    console.log('\nüéâ PRODUCTION PARALLEL INGESTION COMPLETE!');
    console.log('=' * 70);
    console.log(`‚è±Ô∏è  Total time: ${(totalTime / 1000).toFixed(1)}s (${(totalTime / 60000).toFixed(1)} minutes)`);
    console.log(`üìä Items processed: ${allItems.length}`);
    console.log(`üöÄ Speed improvement: ${speedup.toFixed(1)}x faster than original`);
    console.log(`üîí Persistent Storage: ‚úÖ Data permanently stored in EFS`);
    console.log(`üíæ Restart-proof: ‚úÖ Data will survive service restarts`);
    console.log(`üéØ Production ready: ‚úÖ Optimized for production workloads`);

    if (totalTime < 10 * 60 * 1000) { // Less than 10 minutes
      console.log('üèÜ SUCCESS: Production ingestion completed in under 10 minutes!');
    }

  } catch (error) {
    console.error('‚ùå Production parallel ingestion failed:', error);
    console.error('Stack trace:', error.stack);
    process.exit(1);
  }
}

// Performance monitoring
async function main() {
  const memUsage = process.memoryUsage();
  console.log(`üíæ Initial memory usage: ${(memUsage.heapUsed / 1024 / 1024).toFixed(1)}MB`);

  // Verify we're targeting production
  const LANCEDB_API_URL = process.env.LANCEDB_API_URL;
  console.log(`üéØ Target: ${LANCEDB_API_URL}`);

  if (!LANCEDB_API_URL || LANCEDB_API_URL.includes('localhost')) {
    console.error('‚ùå This script requires production LANCEDB_API_URL');
    console.error('Expected: http://lancedb-alb-*.amazonaws.com');
    process.exit(1);
  }

  await productionParallelIngestion();

  const finalMemUsage = process.memoryUsage();
  console.log(`üíæ Final memory usage: ${(finalMemUsage.heapUsed / 1024 / 1024).toFixed(1)}MB`);
}

main().catch(console.error);
